{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Run Instructions:\n","\n","\n","\n","*   Connect to google drive to access files.\n","*   Change file paths to where the datasets (dataset_path) and model files (save_path) are stored.\n","*   Run one model at a time (comment other model code out) to get accurate measurements.\n","*   Restart runtime environement ('Restart session and run all') before every measurement is taken.\n","\n","\n","\n","\n"],"metadata":{"id":"GvOENtYXUI63"}},{"cell_type":"markdown","source":["# Mount Google Drive"],"metadata":{"id":"dY7tfeqZNdmO"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"m8WPMUHwSryH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#File Paths"],"metadata":{"id":"WrUkHWOPA0Ij"}},{"cell_type":"code","source":["save_path = \"/content/drive/MyDrive/CNXSIA001_LAIDS_SOURCE_CODE/PCA-CNN Model Files/Models\" # Model path\n","dataset_path =  \"/content/drive/MyDrive/CNXSIA001_LAIDS_SOURCE_CODE/PCA-CNN Model Files/Datasets\""],"metadata":{"id":"Eqpx_eRoA-6X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import os\n","import numpy as np\n","\n","# Test sets\n","X_test = pd.read_csv(os.path.join(dataset_path, \"pca_cnn_X_test.csv\")).to_numpy()\n","y_test = pd.read_csv(os.path.join(dataset_path, \"pca_cnn_y_test.csv\")).to_numpy().ravel()\n","\n","# Get index of first malicious sample\n","first_malicious_index = np.where(y_test != 0)[0][0]\n","\n","# Extract the sample\n","X_test_sample = X_test[first_malicious_index]\n","y_test_sample = y_test[first_malicious_index]\n","\n","print(f\"X_test_sample: {X_test_sample}\")\n","print(f\"y_test_sample: {y_test_sample}\")\n","\n","# Free up memory\n","del X_test, y_test\n","import gc; gc.collect()"],"metadata":{"id":"3b1doEX5Zfuy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Set CPU Constraints"],"metadata":{"id":"Pqmc4TasVi9A"}},{"cell_type":"code","source":["import os\n","# limit libraries' CPU thread requests to up to 4 threads max to use for parallel computations\n","\n","os.environ['TF_NUM_INTRAOP_THREADS'] = '4' # Only allow TensorFlow to request a max 4 CPU threads per operation (if only 2 threads exist, it only 2 threads are used)\n","os.environ['TF_NUM_INTEROP_THREADS'] = '1'  # Forces TensorFlow to run only one operation at a time\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # reduce Tensorflows output to the console\n","\n","os.environ['OMP_NUM_THREADS'] = '4' # Set the max number of threads the OpenMP (which uses numerical libraries such as NumPy) can request to 4\n","os.environ['MKL_NUM_THREADS'] = '4' # Set the maximum number of threads Intel MKL (Math Kernel Library) can request to 4\n","os.environ['OPENBLAS_NUM_THREADS'] = '4' # Set the maximum number of threads OpenBLAS can request to 4."],"metadata":{"id":"hp0k39XOl1TI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Imports"],"metadata":{"id":"D2NihRdLm-oV"}},{"cell_type":"code","source":["# ---------------\n","# --- Imports ---\n","# ---------------\n","\n","import os\n","import psutil\n","import time\n","import resource\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow.keras.models import load_model, Sequential\n","from tensorflow.keras import layers, regularizers\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\n","from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n"],"metadata":{"id":"Hprzx6shm_js"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Set resource constraints"],"metadata":{"id":"7RvkTflk3B2S"}},{"cell_type":"code","source":["# -------------------------------------------\n","# --- Google Colab Resource Configuration ---\n","# -------------------------------------------\n","\n","def configure_resources_for_colab():\n","    print(\"Configuring Google Colab resources...\")\n","\n","    # Restrict the number of CPU cores to use at most 4\n","    try:\n","        available_cores = min(4, os.cpu_count()) # Limit the CPU cores to be at most 4\n","        os.sched_setaffinity(0, list(range(available_cores))) #limit this current process (0) to run only on the list of available_cores CPU cores.\n","        print(\"Logical cores:\", psutil.cpu_count(logical=True))\n","        print(\"Physical cores:\", psutil.cpu_count(logical=False))\n","    except Exception as e:\n","        print(f\"CPU affinity warning: {e}\")\n","\n","    # Limit Memory to 4GB\n","    try:\n","        memory_limit = 4 * (1024**3)  # 4GB in bytes\n","        resource.setrlimit(resource.RLIMIT_AS, (memory_limit, memory_limit)) #sets the maximum allowed virtual memory this process can use to 4GB (set both soft and hard limits to 4 GB)\n","        print(f\"Memory limit set to 4GB\")\n","    except Exception as e:\n","        print(f\"Memory limit warning: {e}\")\n","\n","    # Print CPU informational\n","    try:\n","        cpu_info = psutil.cpu_freq()\n","        if cpu_info:\n","            print(f\"CPU frequency: {cpu_info.current:.0f}MHz\")\n","        else:\n","            print(f\"CPU frequency info not available\")\n","    except:\n","        print(f\"CPU frequency info not available\")\n","\n","    # Adjust CPU process priority\n","    try:\n","        os.nice(5)  # Lower the CPU priority of the process\n","        print(f\"Process priority lowered\")\n","    except Exception as e:\n","        print(f\"Priority adjustment warning: {e}\")\n","\n","    print(\"Resource configuration complete!\")\n","\n","# Execute function\n","configure_resources_for_colab()\n","\n","\n","# --------------------------------\n","# --- TensorFlow configuration ---\n","# --------------------------------\n","\n","def configure_tensorflow_colab():\n","    print(\"Configuring TensorFlow resources usage...\")\n","\n","    # Reenforce that tensorflow CPU thread usage is limited\n","    try:\n","        tf.config.threading.set_intra_op_parallelism_threads(4) # Only allow TensorFlow to request a max 4 CPU threads per operation (if only 2 threads exist, it only 2 threads are used)\n","        tf.config.threading.set_inter_op_parallelism_threads(1) # Forces TensorFlow to run only one operation at a time\n","        print(\"TensorFlow CPU thread limits configured\")\n","    except RuntimeError as e:\n","        print(\"CPU thread request error\")\n","\n","    tf.get_logger().setLevel('WARNING')# Limit the amount of info tf prints to the console\n","\n","    print(\"TensorFlow configuration complete!\")\n","\n","# Execute function\n","configure_tensorflow_colab()\n","\n","\n","# Get current Colab resource usages\n","def monitor_colab_resources():\n","    try:\n","        # Get memory usage\n","        mem = psutil.virtual_memory()\n","        print(f\"Memory: {mem.used / (1024**3):.1f}GB used out of {mem.total / (1024**3):.1f}GB total ({mem.percent:.1f}%)\")\n","\n","        # Get CPU usage\n","        cpu_percent = psutil.cpu_percent(interval=1)\n","        print(f\"CPU usage: {cpu_percent:.1f}%\")\n","\n","        # Get Disk space\n","        disk = psutil.disk_usage('/')\n","        print(f\"Disk: {disk.used / (1024**3):.1f}GB used out of {disk.total/(1024**3):.1f}GB total ({disk.percent:.1f}%)\")\n","\n","    except Exception as e:\n","        print(f\"Error: {e}\")\n","\n","# Execute function\n","monitor_colab_resources()"],"metadata":{"id":"uirBBsWgZB3U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Resource usage evaluation"],"metadata":{"id":"p8KozpUc213I"}},{"cell_type":"markdown","source":["#FP32 PCA-CNN\n","\n","\n","\n"],"metadata":{"id":"RC-NBwn1H2w4"}},{"cell_type":"code","source":["import os\n","import time\n","import numpy as np\n","import psutil\n","import tensorflow as tf\n","import gc\n","import statistics\n","\n","# -------------------\n","# --- Load model ---\n","# -------------------\n","pca_cnn_model_base = os.path.join(save_path, \"Best_PCA_CNN\")\n","\n","tflite_models = [\n","    {\n","        \"model_path\": pca_cnn_model_base + \"_float32.tflite\",\n","        \"model_name\": \"PCA-CNN Float32 Model\",\n","    }\n","]\n","\n","process = psutil.Process(os.getpid()) #Initialise process instance\n","# ----------------------------\n","# --- Run multiple trials ---\n","# ----------------------------\n","runs = 1000\n","for m in tflite_models:\n","    start_mem = process.memory_info().rss / (1024**2) # Start memory usage\n","\n","    # --- Load interpreter ---\n","    interpreter = tf.lite.Interpreter(model_path=m[\"model_path\"])\n","    interpreter.allocate_tensors()\n","    input_details = interpreter.get_input_details()\n","    output_details = interpreter.get_output_details()\n","\n","    wall_times, the_cpu_seconds = [], []\n","\n","    for _ in range(runs):\n","        # Record start processing times\n","        start_time = time.time()\n","        start_cpu_times = process.cpu_times()\n","\n","\n","        # --- PCA-CNN inference ---\n","        # Shape input\n","        sample_input = np.expand_dims(X_test_sample, axis=0)   # (1, timesteps)\n","        sample_input = np.expand_dims(sample_input, axis=-1)   # (1, timesteps, 1)\n","        sample_input = sample_input.astype(input_details[0]['dtype']) # Change datatype\n","\n","        interpreter.set_tensor(input_details[0]['index'], sample_input)\n","        interpreter.invoke()\n","        output_data = interpreter.get_tensor(output_details[0]['index'])\n","        y_pred = np.argmax(output_data, axis=1) # get output prediction\n","\n","        # Record end processing time\n","        end_time = time.time()\n","        end_cpu_times = process.cpu_times()\n","\n","\n","        # Compute total processing times\n","        wall_clock = end_time - start_time\n","        cpu_seconds = (end_cpu_times.user + end_cpu_times.system) - (start_cpu_times.user + start_cpu_times.system)\n","\n","        # Append times to lists\n","        wall_times.append(wall_clock)\n","        the_cpu_seconds.append(cpu_seconds)\n","\n","    # Get end memeory usage and calc. total memory usage\n","    end_mem = process.memory_info().rss / (1024**2)\n","    total_ram_change = end_mem - start_mem\n","    ram_change_per_sample = total_ram_change / runs\n","\n","    # --- Report average results ---\n","    print(f\"\\nResults for {m['model_name']} over {runs} runs:\")\n","    print(f\"Inference wall-clock time: {statistics.mean(wall_times):.10f} ± {statistics.stdev(wall_times):.10f} sec\")\n","    print(f\"CPU seconds: {statistics.mean(the_cpu_seconds):.10f} ± {statistics.stdev(the_cpu_seconds):.10f} sec\")\n","\n","    print(f\"RAM change: {total_ram_change:.10f} MB\")\n","    print(f\"RAM change per sample: {ram_change_per_sample:.10f} MB\")\n","\n","    # --- Report average results converted ---\n","    print(f\"\\nResults for {m['model_name']} over {runs} runs:\")\n","    print(f\"Inference wall-clock time: {statistics.mean(wall_times)*1000:.4f} ± {statistics.stdev(wall_times)*1000:.4f} ms\")\n","    print(f\"CPU time: {statistics.mean(the_cpu_seconds)*1000:.4f} ± {statistics.stdev(the_cpu_seconds)*1000:.4f} ms\")\n","\n","    print(f\"RAM change over {runs} runs: {total_ram_change*1024:.4f} KB\")\n","    print(f\"RAM change per sample: {ram_change_per_sample*1024:.4f} KB\")\n","\n","    # Model file sizes\n","    pca_cnn_size_mb = os.path.getsize(m[\"model_path\"]) / (1024**2)\n","    print(f\"PCA-CNN model size: {pca_cnn_size_mb:.4f} MB\")\n","\n"],"metadata":{"id":"xxRadtEMFl-p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["FP32 Results\n","\n","\n","```\n","Results for PCA-CNN Float32 Model over 1000 runs:\n","Inference wall-clock time: 0.0000810235 ± 0.0000733856 sec\n","CPU seconds: 0.0000900000 ± 0.0009448771 sec\n","CPU usage: 58.3548% ± 615.9829%\n","RAM change: 3.1562 MB (to run all 100 samples)\n","PCA-CNN model size: 0.0194 MB\n","```\n","\n","\n","```\n","esults for PCA-CNN Float32 Model over 1000 runs:\n","Inference wall-clock time: 0.0000528476 ± 0.0000250624 sec\n","CPU seconds: 0.0000700000 ± 0.0008341438 sec\n","CPU usage: 75.4640% ± 899.6694%\n","RAM change: 2.7812 MB (to run all 100 samples)\n","PCA-CNN model size: 0.0194 MB\n","```\n","\n","\n","```\n","Results for PCA-CNN Float32 Model over 1000 runs:\n","Inference wall-clock time: 0.0000495875 ± 0.0000119537 sec\n","CPU seconds: 0.0000500000 ± 0.0007056897 sec\n","CPU usage: 54.9637% ± 775.7949%\n","RAM change: 2.5820 MB (to run all 100 samples)\n","PCA-CNN model size: 0.0194 MB\n","```\n","\n","\n","\n","```\n","Results for PCA-CNN Float32 Model over 1000 runs:\n","Inference wall-clock time: 0.0000535252 ± 0.0000167828 sec\n","CPU seconds: 0.0000600000 ± 0.0007726558 sec\n","CPU usage: 50.5205% ± 683.7242%\n","RAM change: 2.5234 MB (to run all 100 samples)\n","PCA-CNN model size: 0.0194 MB\n","```\n","\n","\n","```\n","Results for PCA-CNN Float32 Model over 1000 runs:\n","Inference wall-clock time: 0.0000520182 ± 0.0000150431 sec\n","CPU seconds: 0.0000300000 ± 0.0005471740 sec\n","CPU usage: 27.2157% ± 505.8965%\n","RAM change: 2.4648 MB (to run all 100 samples)\n","PCA-CNN model size: 0.0194 MB\n","```\n","\n","Average values per sample:\n","\n","```\n","Inference wall-clock time: 0.0578 ms\n","CPU seconds: 0.06 ms\n","RAM change: 2.76635648 KB\n","PCA-CNN model size: 0.0194 MB\n","```\n","\n","\n","\n","\n"],"metadata":{"id":"0sXDAkHHMwDw"}},{"cell_type":"markdown","source":["#FP16 PCA-CNN\n","\n"],"metadata":{"id":"esGX2qiRH59C"}},{"cell_type":"code","source":["import os\n","import time\n","import numpy as np\n","import psutil\n","import tensorflow as tf\n","import gc\n","import statistics\n","\n","# -------------------\n","# --- Load models ---\n","# -------------------\n","\n","\n","pca_cnn_model_base = os.path.join(save_path, \"Best_PCA_CNN\")\n","\n","tflite_models = [\n","    {\n","        \"model_path\": pca_cnn_model_base + \"_fp16_weights.tflite\",\n","        \"model_name\": \"PCA-CNN Float16 Model\",\n","    }\n","]\n","\n","process = psutil.Process(os.getpid()) #Initialise process instance\n","# ----------------------------\n","# --- Run multiple trials ---\n","# ----------------------------\n","runs = 1000\n","for m in tflite_models:\n","    start_mem = process.memory_info().rss / (1024**2) # Start memory usage\n","\n","    # --- Load interpreter ---\n","    interpreter = tf.lite.Interpreter(model_path=m[\"model_path\"])\n","    interpreter.allocate_tensors()\n","    input_details = interpreter.get_input_details()\n","    output_details = interpreter.get_output_details()\n","\n","    wall_times, the_cpu_seconds = [], []\n","\n","    for _ in range(runs):\n","        # Record start processing times\n","        start_time = time.time()\n","        start_cpu_times = process.cpu_times()\n","\n","\n","        # --- PCA-CNN inference ---\n","        sample_input = np.expand_dims(X_test_sample, axis=0)   # (1, timesteps)\n","        sample_input = np.expand_dims(sample_input, axis=-1)   # (1, timesteps, 1)\n","        sample_input = sample_input.astype(input_details[0]['dtype']) # Change datatype\n","\n","        interpreter.set_tensor(input_details[0]['index'], sample_input)\n","        interpreter.invoke()\n","        output_data = interpreter.get_tensor(output_details[0]['index'])\n","        y_pred = np.argmax(output_data, axis=1) # get output prediction\n","\n","        # Record end processing time\n","        end_time = time.time()\n","        end_cpu_times = process.cpu_times()\n","\n","\n","        # Compute total processing times\n","        wall_clock = end_time - start_time\n","        cpu_seconds = (end_cpu_times.user + end_cpu_times.system) - (start_cpu_times.user + start_cpu_times.system)\n","\n","        # Append times to lists\n","        wall_times.append(wall_clock)\n","        the_cpu_seconds.append(cpu_seconds)\n","\n","    # Get end memeory usage and calc. total memory usage\n","    end_mem = process.memory_info().rss / (1024**2)\n","    total_ram_change = end_mem - start_mem\n","    ram_change_per_sample = total_ram_change / runs\n","\n","    # --- Report average results ---\n","    print(f\"\\nResults for {m['model_name']} over {runs} runs:\")\n","    print(f\"Inference wall-clock time: {statistics.mean(wall_times):.10f} ± {statistics.stdev(wall_times):.10f} sec\")\n","    print(f\"CPU seconds: {statistics.mean(the_cpu_seconds):.10f} ± {statistics.stdev(the_cpu_seconds):.10f} sec\")\n","\n","    print(f\"RAM change: {total_ram_change:.10f} MB\")\n","    print(f\"RAM change per sample: {ram_change_per_sample:.10f} MB\")\n","\n","    # --- Report average results converted ---\n","    print(f\"\\nResults for {m['model_name']} over {runs} runs:\")\n","    print(f\"Inference wall-clock time: {statistics.mean(wall_times)*1000:.4f} ± {statistics.stdev(wall_times)*1000:.4f} ms\")\n","    print(f\"CPU time: {statistics.mean(the_cpu_seconds)*1000:.4f} ± {statistics.stdev(the_cpu_seconds)*1000:.4f} ms\")\n","\n","    print(f\"RAM change over {runs} runs: {total_ram_change*1024:.4f} KB\")\n","    print(f\"RAM change per sample: {ram_change_per_sample*1024:.4f} KB\")\n","\n","    # Model file sizes\n","    pca_cnn_size_mb = os.path.getsize(m[\"model_path\"]) / (1024**2)\n","    print(f\"FP16 PCA-CNN model size: {pca_cnn_size_mb:.4f} MB\")"],"metadata":{"id":"l6jhI_ix03FN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["FP16 Results\n","\n","\n","```\n","Results for PCA-CNN Float16 Model over 1000 runs:\n","Inference wall-clock time: 0.0001162429 ± 0.0000773989 sec\n","CPU seconds: 0.0001200000 ± 0.0010893974 sec\n","CPU usage: 50.4393% ± 466.5665%\n","RAM change: 2.5430 MB\n","\n","Wall-clock time in ms: 0.1162429 ms\n","CPU time in ms: 0.12 ms\n","RAM per sample in KB: 2.604032  KB\n","PCA-CNN model size: 0.0145 MB\n","```\n","\n","```\n","Results for PCA-CNN Float16 Model over 1000 runs:\n","Inference wall-clock time: 0.0000543382 ± 0.0000185768 sec\n","CPU seconds: 0.0000200000 ± 0.0004469897 sec\n","CPU usage: 19.5695% ± 439.0603%\n","RAM change: 2.3516 MB\n","\n","Wall-clock time in ms: 0.0543382 ms\n","CPU time in ms: 0.02 ms\n","RAM per sample in KB: 2.4080384  KB\n","PCA-CNN model size: 0.0145 MB\n","```\n","\n","\n","\n","```\n","Results for PCA-CNN Float16 Model over 1000 runs:\n","Inference wall-clock time: 0.0000529754 ± 0.0000189002 sec\n","CPU seconds: 0.0000600000 ± 0.0007726558 sec\n","CPU usage: 44.3254% ± 604.0242%\n","RAM change: 1.9297 MB\n","\n","Wall-clock time in ms: 0.0529754 ms\n","CPU time in ms: 0.06 ms\n","RAM per sample in KB: 1.9760128  KB\n","PCA-CNN model size: 0.0145 MB\n","```\n","\n","\n","\n","```\n","Results for PCA-CNN Float16 Model over 1000 runs:\n","Inference wall-clock time: 0.0000522676 ± 0.0000184107 sec\n","CPU seconds: 0.0000600000 ± 0.0007726558 sec\n","CPU usage: 63.5182% ± 818.1007%\n","RAM change: 2.1719 MB\n","\n","Wall-clock time in ms: 0.0522676 ms\n","CPU time in ms: 0.06 ms\n","RAM per sample in KB: 2.2240256  KB\n","PCA-CNN model size: 0.0145 MB\n","```\n","\n","\n","\n","```\n","Results for PCA-CNN Float16 Model over 1000 runs:\n","Inference wall-clock time: 0.0000516663 ± 0.0000135741 sec\n","CPU seconds: 0.0000700000 ± 0.0008341438 sec\n","CPU usage: 69.6367% ± 845.2789%\n","RAM change: 2.2188 MB\n","\n","Wall-clock time in ms: 0.0516663 ms\n","CPU time in ms: 0.07 ms\n","RAM per sample in KB: 2.2720512  KB\n","PCA-CNN model size: 0.0145 MB\n","```\n","\n","\n","\n","\n"],"metadata":{"id":"3CKOP8EoReiU"}},{"cell_type":"markdown","source":["#Dynamic INT8 PCA-CNN\n","\n","\n"],"metadata":{"id":"6gtH0zoLM0jb"}},{"cell_type":"code","source":["import os\n","import time\n","import numpy as np\n","import psutil\n","import tensorflow as tf\n","import gc\n","import statistics\n","\n","# -------------------\n","# --- Load models ---\n","# -------------------\n","\n","\n","pca_cnn_model_base = os.path.join(save_path, \"Best_PCA_CNN\")\n","\n","tflite_models = [\n","    {\n","        \"model_path\": pca_cnn_model_base + \"_int8_weights.tflite\",\n","        \"model_name\": \"PCA-CNN Dyamic INT8 Model\",\n","    }\n","]\n","\n","process = psutil.Process(os.getpid()) #Initialise process instance\n","# ----------------------------\n","# --- Run multiple trials ---\n","# ----------------------------\n","runs = 1000\n","for m in tflite_models:\n","    start_mem = process.memory_info().rss / (1024**2) # Start memory usage\n","\n","    # --- Load interpreter ---\n","    interpreter = tf.lite.Interpreter(model_path=m[\"model_path\"])\n","    interpreter.allocate_tensors()\n","    input_details = interpreter.get_input_details()\n","    output_details = interpreter.get_output_details()\n","\n","    wall_times, the_cpu_seconds = [], []\n","\n","    for _ in range(runs):\n","        # Record start processing times\n","        start_time = time.time()\n","        start_cpu_times = process.cpu_times()\n","\n","\n","        # --- PCA-CNN inference ---\n","        sample_input = np.expand_dims(X_test_sample, axis=0)   # (1, timesteps)\n","        sample_input = np.expand_dims(sample_input, axis=-1)   # (1, timesteps, 1)\n","        sample_input = sample_input.astype(input_details[0]['dtype']) # Change datatype\n","\n","        interpreter.set_tensor(input_details[0]['index'], sample_input)\n","        interpreter.invoke()\n","        output_data = interpreter.get_tensor(output_details[0]['index'])\n","        y_pred = np.argmax(output_data, axis=1) # get output prediction\n","\n","        # Record end processing time\n","        end_time = time.time()\n","        end_cpu_times = process.cpu_times()\n","\n","\n","        # Compute total processing times\n","        wall_clock = end_time - start_time\n","        cpu_seconds = (end_cpu_times.user + end_cpu_times.system) - (start_cpu_times.user + start_cpu_times.system)\n","\n","        # Append times to lists\n","        wall_times.append(wall_clock)\n","        the_cpu_seconds.append(cpu_seconds)\n","\n","    # Get end memeory usage and calc. total memory usage\n","    end_mem = process.memory_info().rss / (1024**2)\n","    total_ram_change = end_mem - start_mem\n","    ram_change_per_sample = total_ram_change / runs\n","\n","    # --- Report average results ---\n","    print(f\"\\nResults for {m['model_name']} over {runs} runs:\")\n","    print(f\"Inference wall-clock time: {statistics.mean(wall_times):.10f} ± {statistics.stdev(wall_times):.10f} sec\")\n","    print(f\"CPU seconds: {statistics.mean(the_cpu_seconds):.10f} ± {statistics.stdev(the_cpu_seconds):.10f} sec\")\n","\n","    print(f\"RAM change: {total_ram_change:.10f} MB\")\n","    print(f\"RAM change per sample: {ram_change_per_sample:.10f} MB\")\n","\n","    # --- Report average results converted ---\n","    print(f\"\\nResults for {m['model_name']} over {runs} runs:\")\n","    print(f\"Inference wall-clock time: {statistics.mean(wall_times)*1000:.4f} ± {statistics.stdev(wall_times)*1000:.4f} ms\")\n","    print(f\"CPU time: {statistics.mean(the_cpu_seconds)*1000:.4f} ± {statistics.stdev(the_cpu_seconds)*1000:.4f} ms\")\n","\n","    print(f\"RAM change over {runs} runs: {total_ram_change*1024:.4f} KB\")\n","    print(f\"RAM change per sample: {ram_change_per_sample*1024:.4f} KB\")\n","\n","    # Model file sizes\n","    pca_cnn_size_mb = os.path.getsize(m[\"model_path\"]) / (1024**2)\n","    print(f\"Dynamic INT8 PCA-CNN model size: {pca_cnn_size_mb:.4f} MB\")"],"metadata":{"id":"rxIj37vjXH_c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Dynamic INT8 Results\n","\n","\n","```\n","Results for PCA-CNN Dyamic INT8 Model over 1000 runs:\n","Inference wall-clock time: 0.0590 ± 0.0219 ms\n","CPU time: 0.0400 ± 0.6315 ms\n","CPU usage: 34.8712% ± 563.7609%\n","RAM change over 1000 runs: 3284.0000 KB\n","RAM change per sample: 3.2840 KB\n","PCA-CNN model size: 0.0131 MB\n","\n","\n","Results for PCA-CNN Dyamic INT8 Model over 1000 runs:\n","Inference wall-clock time: 0.0463 ± 0.0177 ms\n","CPU time: 0.0800 ± 0.8913 ms\n","CPU usage: 89.8685% ± 1012.8645%\n","RAM change over 1000 runs: 3516.0000 KB\n","RAM change per sample: 3.5160 KB\n","PCA-CNN model size: 0.0131 MB\n","\n","\n","Results for PCA-CNN Dyamic INT8 Model over 1000 runs:\n","Inference wall-clock time: 0.0647 ± 0.0220 ms\n","CPU time: 0.0700 ± 0.8341 ms\n","CPU usage: 41.2045% ± 537.4772%\n","RAM change over 1000 runs: 3468.0000 KB\n","RAM change per sample: 3.4680 KB\n","PCA-CNN model size: 0.0131 MB\n","\n","\n","Results for PCA-CNN Dyamic INT8 Model over 1000 runs:\n","Inference wall-clock time: 0.0439 ± 0.0232 ms\n","CPU time: 0.0600 ± 0.7727 ms\n","CPU usage: 75.8307% ± 977.7052%\n","RAM change over 1000 runs: 3484.0000 KB\n","RAM change per sample: 3.4840 KB\n","PCA-CNN model size: 0.0131 MB\n","\n","\n","Results for PCA-CNN Dyamic INT8 Model over 1000 runs:\n","Inference wall-clock time: 0.0546 ± 0.0158 ms\n","CPU time: 0.0800 ± 0.8913 ms\n","CPU usage: 74.8440% ± 840.2827%\n","RAM change over 1000 runs: 3728.0000 KB\n","RAM change per sample: 3.7280 KB\n","PCA-CNN model size: 0.0131 MB\n","\n","```\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"u1XRCp0dXSxm"}},{"cell_type":"markdown","source":["#Full INT8 PCA-CNN\n","\n","\n","\n"],"metadata":{"id":"7h1gtoJUNCbb"}},{"cell_type":"code","source":["import os\n","import time\n","import numpy as np\n","import psutil\n","import tensorflow as tf\n","import gc\n","import statistics\n","\n","# -------------------\n","# --- Load models ---\n","# -------------------\n","\n","\n","pca_cnn_model_base = os.path.join(save_path, \"Best_PCA_CNN\")\n","\n","tflite_models = [\n","    {\n","        \"model_path\": pca_cnn_model_base + \"_int8_full.tflite\",\n","        \"model_name\": \"PCA-CNN Full INT8 Model\",\n","    }\n","]\n","\n","process = psutil.Process(os.getpid()) #Initialise process instance\n","# ----------------------------\n","# --- Run multiple trials ---\n","# ----------------------------\n","runs = 1000\n","for m in tflite_models:\n","    start_mem = process.memory_info().rss / (1024**2)\n","\n","    # --- Load interpreters once ---\n","    interpreter = tf.lite.Interpreter(model_path=m[\"model_path\"])\n","    interpreter.allocate_tensors()\n","    input_details = interpreter.get_input_details()\n","    output_details = interpreter.get_output_details()\n","\n","    wall_times, the_cpu_seconds = [], []\n","\n","    for _ in range(runs):\n","        # Record processing time start values\n","        start_time = time.time()\n","        start_cpu_times = process.cpu_times()\n","\n","\n","        # --- PCA-CNN inference ---\n","        # get scaling and sero point values for quanitsation of input sample\n","        in_scale, in_zp = input_details[0]['quantization']\n","        out_scale, out_zp = output_details[0]['quantization']\n","\n","        # Reshape input\n","        sample_input = np.expand_dims(X_test_sample, axis=0)   # (1, timesteps)\n","        sample_input = np.expand_dims(sample_input, axis=-1)   # (1, timesteps, 1)\n","\n","        # Quantise input for int8 model\n","        if input_details[0]['dtype'] == np.int8:\n","            quant_sample_input = np.round(sample_input / in_scale + in_zp).astype(np.int8) # quant input + change its datatype\n","\n","        # Model processes input\n","        interpreter.set_tensor(input_details[0]['index'], quant_sample_input)\n","        interpreter.invoke()\n","        quant_sample_output = interpreter.get_tensor(output_details[0]['index'])\n","\n","        # Dequantise output back to float32\n","        if output_details[0]['dtype'] == np.int8: # Corrected index here\n","            output_data = (quant_sample_output.astype(np.float32) - out_zp) * out_scale\n","\n","        y_pred = np.argmax(output_data, axis=1) # get final predictions\n","\n","\n","        # Record processing time end values\n","        end_time = time.time()\n","        end_cpu_times = process.cpu_times()\n","        end_mem = process.memory_info().rss / (1024**2)\n","\n","        # Compute processing time totals\n","        wall_clock = end_time - start_time\n","        cpu_seconds = (end_cpu_times.user + end_cpu_times.system) - (start_cpu_times.user + start_cpu_times.system)\n","\n","        # Append times to lists\n","        wall_times.append(wall_clock)\n","        the_cpu_seconds.append(cpu_seconds)\n","\n","    # Compute total memory usage\n","    end_mem = process.memory_info().rss / (1024**2)\n","    total_ram_change = end_mem - start_mem\n","    ram_change_per_sample = total_ram_change / runs # memory per sample run\n","\n","    # --- Report average results ---\n","    print(f\"\\nResults for {m['model_name']} over {runs} runs:\")\n","    print(f\"Inference wall-clock time: {statistics.mean(wall_times):.10f} ± {statistics.stdev(wall_times):.10f} sec\")\n","    print(f\"CPU seconds: {statistics.mean(the_cpu_seconds):.10f} ± {statistics.stdev(the_cpu_seconds):.10f} sec\")\n","\n","    print(f\"RAM change: {total_ram_change:.10f} MB\")\n","    print(f\"RAM change per sample: {ram_change_per_sample:.10f} MB\")\n","\n","    # --- Report average results converted ---\n","    print(f\"\\nResults for {m['model_name']} over {runs} runs:\")\n","    print(f\"Inference wall-clock time: {statistics.mean(wall_times)*1000:.4f} ± {statistics.stdev(wall_times)*1000:.4f} ms\")\n","    print(f\"CPU time: {statistics.mean(the_cpu_seconds)*1000:.4f} ± {statistics.stdev(the_cpu_seconds)*1000:.4f} ms\")\n","\n","    print(f\"RAM change over {runs} runs: {total_ram_change*1024:.4f} KB\")\n","    print(f\"RAM change per sample: {ram_change_per_sample*1024:.4f} KB\")\n","\n","    # Model file sizes\n","    pca_cnn_size_mb = os.path.getsize(m[\"model_path\"]) / (1024**2)\n","    print(f\"Full INT8 PCA-CNN model size: {pca_cnn_size_mb:.4f} MB\")"],"metadata":{"id":"QwhoyovnNEx8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Full INT8 Results\n","\n","\n","\n","```\n","Results for PCA-CNN Full INT8 Model over 1000 runs:\n","Inference wall-clock time: 0.0760 ± 0.0225 ms\n","CPU time: 0.0300 ± 0.5472 ms\n","CPU usage: 21.2098% ± 387.2934%\n","RAM change over 1000 runs: 2232.0000 KB\n","RAM change per sample: 2.2320 KB\n","PCA-CNN model size: 0.0141 MB\n","```\n","\n","\n","```\n","Results for PCA-CNN Full INT8 Model over 1000 runs:\n","Inference wall-clock time: 0.0769 ± 0.0176 ms\n","CPU time: 0.0800 ± 0.8913 ms\n","CPU usage: 45.3665% ± 529.0984%\n","RAM change over 1000 runs: 2376.0000 KB\n","RAM change per sample: 2.3760 KB\n","PCA-CNN model size: 0.0141 MB\n","```\n","\n","\n","```\n","Results for PCA-CNN Full INT8 Model over 1000 runs:\n","Inference wall-clock time: 0.0807 ± 0.0297 ms\n","CPU time: 0.1100 ± 1.0435 ms\n","CPU usage: 74.3576% ± 714.5987%\n","RAM change over 1000 runs: 2400.0000 KB\n","RAM change per sample: 2.4000 KB\n","PCA-CNN model size: 0.0141 MB\n","```\n","\n","\n","\n","```\n","Results for PCA-CNN Full INT8 Model over 1000 runs:\n","Inference wall-clock time: 0.1452 ± 0.1137 ms\n","CPU time: 0.1000 ± 0.9955 ms\n","CPU usage: 41.1684% ± 424.7923%\n","RAM change over 1000 runs: 2172.0000 KB\n","RAM change per sample: 2.1720 KB\n","PCA-CNN model size: 0.0141 MB\n","```\n","\n","\n","```\n","Results for PCA-CNN Full INT8 Model over 1000 runs:\n","Inference wall-clock time: 0.0876 ± 0.0357 ms\n","CPU time: 0.0900 ± 0.9449 ms\n","CPU usage: 54.4493% ± 597.8247%\n","RAM change over 1000 runs: 2052.0000 KB\n","RAM change per sample: 2.0520 KB\n","PCA-CNN model size: 0.0141 MB\n","```\n","\n","\n"],"metadata":{"id":"lGS7D4oYVujC"}}]}